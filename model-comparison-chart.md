# AI Model Comparison Chart - February 2026

## Quick Comparison Matrix

| Model | Input Cost | Output Cost | Speed | Coding | Math | Vision | Reasoning | Context | Best For |
|-------|-----------|-------------|-------|--------|------|--------|-----------|---------|----------|
| **GPT-5.2-Codex** | $1.75/M | $14/M | âš¡âš¡âš¡ | 7/10 | 10/10 | 6/10 | 9/10 | 200K | Default, Math, General |
| **GPT-5.3-Codex** | ~$2/M | ~$16/M | âš¡âš¡âš¡âš¡ | 8/10 | 10/10 | 6/10 | 9/10 | 200K | Speed-critical tasks |
| **Sonnet 4.5** | ~$3/M | ~$15/M | âš¡âš¡âš¡ | 9/10 | 8/10 | 7/10 | 8/10 | 200K | Balanced, Chat, Code |
| **Opus 4.5** | $5/M | $25/M | âš¡âš¡ | 10/10 | 9/10 | 7/10 | 10/10 | 200K | Complex code, Deep reasoning |
| **Opus 4.6** | $5/M | $25/M | âš¡âš¡ | 10/10 | 9/10 | 7/10 | 10/10 | 1M | Long context, Finance |
| **Gemini 3 Pro** | $2/M | $12/M | âš¡âš¡ | 6/10 | 7/10 | 10/10 | 8/10 | 1M | Vision, Multimodal, Long docs |

**Rating Scale:** 1-10 (10 = best in class)

---

## Benchmark Scores (Key Metrics)

### SWE-bench Verified (Real-world Coding)
*Higher is better - measures ability to solve real software engineering problems*

```
Claude Opus 4.5:    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 80.9% ğŸ† #1
Claude Sonnet 4.5:  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   77.2%
GPT-5.2-Codex:      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ        55.6%
Gemini 3 Pro:       â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ          ~52%
```

**Winner: Opus 4.5** - First model to break 80% barrier

---

### AIME 2025 (Mathematical Reasoning)
*Higher is better - measures math problem-solving at competition level*

```
GPT-5.2:            â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 100% ğŸ† #1
Claude Opus 4.5:    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     ~80%
Gemini 3 Pro:       â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ       ~70%
Claude Sonnet 4.5:  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ        ~65%
```

**Winner: GPT-5.2** - Perfect score, unmatched math capability

---

### ARC-AGI-2 (Abstract Reasoning)
*Higher is better - measures fluid intelligence and novel problem-solving*

```
GPT-5.2:            â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 52.9% ğŸ† #1
Gemini 3 Pro:       â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   45.1%
Claude Opus 4.5:    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      37.6%
Claude Sonnet 4.5:  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ        ~33%
```

**Winner: GPT-5.2** - Best at abstract, novel reasoning

---

### Long Context Recall (MRCR v2, 1M tokens)
*Higher is better - measures ability to find and use information in long contexts*

```
Claude Opus 4.6:    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 76.0% ğŸ† #1
Gemini 3 Pro:       â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     ~65%
Claude Sonnet 4.5:  â–ˆâ–ˆâ–ˆâ–ˆ                 18.5%
GPT-5.2:            N/A                  (200K context only)
```

**Winner: Opus 4.6** - Breakthrough long-context performance

---

## Cost Efficiency Analysis

### Cost per 1K Requests (Standard Workload)
*Assuming 1.5K input tokens, 500 output tokens per request*

```
GPT-5.2-Codex:      â–ˆâ–ˆâ–ˆ $9.63            ğŸ† Cheapest
Gemini 3 Pro:       â–ˆâ–ˆâ–ˆâ–ˆ $9.00           (but rate limits!)
Sonnet 4.5:         â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ $12.00
Opus 4.5:           â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ $20.00
```

**Winner: GPT-5.2-Codex** - Best cost/performance ratio at scale

---

### Speed Comparison (Median Latency)

```
GPT-5.3-Codex:      âš¡âš¡âš¡âš¡ ~2.2s      ğŸ† Fastest
GPT-5.2-Codex:      âš¡âš¡âš¡ ~2.8s
Sonnet 4.5:         âš¡âš¡âš¡ ~3.0s
Gemini 3 Pro:       âš¡âš¡ ~3.8s
Opus 4.5:           âš¡âš¡ ~4.5s
```

**Winner: GPT-5.3-Codex** - 25% faster than 5.2

---

## Use Case Recommendations

### 1. General Conversational AI
**Best choice:** Claude Sonnet 4.5
- Most natural, human-like responses
- Excellent safety and alignment
- Fast and reliable

**Alternative:** GPT-5.2-Codex (if cost matters more)

---

### 2. Code Generation & Review
**Simple tasks:** GPT-5.2-Codex or Sonnet 4.5
**Complex debugging:** Claude Opus 4.5 (80.9% accuracy)
**Code review:** Sonnet 4.5 (41% important bug detection)

---

### 3. Mathematical & Scientific Work
**Best choice:** GPT-5.2-Codex
- 100% AIME score
- Unmatched mathematical reasoning
- Strong abstract problem-solving

**No alternative** - GPT-5.2 dominates this category

---

### 4. Vision & Multimodal Tasks
**Best choice:** Gemini 3 Pro
- Native video, audio, image understanding
- Superior visual reasoning
- Integrated multimodal processing

**Alternative:** Sonnet 4.5 (acceptable for images only)

---

### 5. Long Documents (>200K tokens)
**Best choice:** Gemini 3 Pro or Opus 4.6
- Both support 1M token context
- Opus 4.6 better recall (76% vs ~65%)
- Gemini cheaper ($2/$12 vs $5/$25)

---

### 6. Deep Analysis & Reasoning
**Best choice:** Claude Opus 4.5
- Reasoning score: 70 (highest)
- Excellent for complex, multi-step problems
- Strong at architectural decisions

**Alternative:** GPT-5.2-Codex (good at abstract reasoning)

---

### 7. Speed-Critical Interactive Work
**Best choice:** GPT-5.3-Codex
- 25% faster than GPT-5.2
- Optimized for agentic workflows
- Best for real-time coding assistance

---

### 8. Cost-Sensitive Batch Processing
**Best choice:** GPT-5.2-Codex
- Cheapest input tokens ($1.75/M)
- Competitive output tokens ($14/M)
- Fast enough for most tasks

---

## Model Selection Decision Tree

```
START: What's your primary need?
â”‚
â”œâ”€ [VISION/IMAGES] â†’ Gemini 3 Pro
â”‚   â””â”€ Has images/video/audio? YES â†’ Gemini 3 Pro
â”‚   â””â”€ NO â†’ Continue below...
â”‚
â”œâ”€ [SPEED CRITICAL] â†’ GPT-5.3-Codex
â”‚   â””â”€ Need fastest response? YES â†’ GPT-5.3-Codex
â”‚   â””â”€ NO â†’ Continue below...
â”‚
â”œâ”€ [COMPLEX CODING] â†’ Claude Opus 4.5
â”‚   â””â”€ Multi-file debugging or critical code? YES â†’ Opus 4.5
â”‚   â””â”€ NO â†’ Continue below...
â”‚
â”œâ”€ [MATH/LOGIC] â†’ GPT-5.2-Codex
â”‚   â””â”€ Mathematical or abstract reasoning? YES â†’ GPT-5.2-Codex
â”‚   â””â”€ NO â†’ Continue below...
â”‚
â”œâ”€ [LONG DOCUMENTS] â†’ Gemini 3 Pro or Opus 4.6
â”‚   â””â”€ More than 200K tokens? YES â†’ Gemini 3 Pro (cheaper) or Opus 4.6 (better)
â”‚   â””â”€ NO â†’ Continue below...
â”‚
â”œâ”€ [DEEP REASONING] â†’ Claude Opus 4.5
â”‚   â””â”€ Complex analysis or planning? YES â†’ Opus 4.5
â”‚   â””â”€ NO â†’ Continue below...
â”‚
â”œâ”€ [NATURAL CHAT] â†’ Claude Sonnet 4.5
â”‚   â””â”€ Human-like conversation? YES â†’ Sonnet 4.5
â”‚   â””â”€ NO â†’ Continue below...
â”‚
â””â”€ [DEFAULT] â†’ GPT-5.2-Codex
    â””â”€ Best all-around value
```

---

## Pricing Summary (February 2026)

### Per 1 Million Tokens

| Model | Input | Output | Total (1M in + 1M out) |
|-------|-------|--------|------------------------|
| **GPT-5.2-Codex** | $1.75 | $14.00 | $15.75 |
| **GPT-5.3-Codex** | ~$2.00 | ~$16.00 | ~$18.00 |
| **Gemini 3 Pro** | $2.00 | $12.00 | $14.00 |
| **Sonnet 4.5** | ~$3.00 | ~$15.00 | ~$18.00 |
| **Opus 4.5** | $5.00 | $25.00 | $30.00 |
| **Opus 4.6** | $5.00 | $25.00 | $30.00 |

**Note:** Sonnet 4.5 pricing is estimated; Anthropic hasn't published exact figures.

---

## Rate Limits Overview

### OpenAI (GPT models)
- **Free tier:** Limited (not suitable for production)
- **Tier 1:** ~10,000 RPM
- **Tier 4-5:** ~50,000+ RPM
- **Scaling:** Based on usage and payment history

### Anthropic (Claude models)
- **Free tier:** Very limited
- **Standard paid:** ~50,000 RPM
- **Enterprise:** Custom limits
- **Burst capacity:** Good for spike traffic

### Google (Gemini models)
- **Free tier:** âš ï¸ 5-15 RPM (NOT suitable for production)
- **Paid Tier 1:** 150-300 RPM
- **Paid Tier 2:** 500+ RPM
- **âš ï¸ Recommendation:** MUST upgrade to paid tier for any real usage

---

## Thinking Modes Comparison

### Claude Extended Thinking
- **Regular mode:** Standard reasoning
- **Extended thinking:** Deep, step-by-step analysis
- **Cost:** Additional tokens for reasoning (shown in output)
- **Use when:** Complex problems need careful analysis

### Gemini Thinking Levels
- **Low thinking:** Faster, cheaper, simple tasks
- **High thinking:** Better reasoning, complex analysis
- **Cost:** Different pricing for different levels
- **Use when:** Can tune cost/quality tradeoff per request

### GPT-5 Reasoning
- **Built-in:** Strong reasoning by default
- **No separate mode:** Single model capability
- **Cost:** Standard pricing applies
- **Use when:** Mathematical or abstract reasoning needed

---

## Model Availability & Stability

### Production-Ready (Stable)
âœ… **GPT-5.2-Codex** - Stable, released Jan 2026  
âœ… **GPT-5.3-Codex** - Stable, released Feb 2026  
âœ… **Claude Sonnet 4.5** - Stable, released Sept 2025  
âœ… **Claude Opus 4.5** - Stable, released Nov 2025  
âœ… **Claude Opus 4.6** - Stable, released Feb 2026  

### Preview/Beta (Use with caution)
âš ï¸ **Gemini 3 Pro Preview** - Still in preview, pricing may change  
- Expected stable release: Q2 2026
- Pricing may drop to $1.50/$10
- Rate limits improving

---

## Context Window Comparison

| Model | Context Window | Notes |
|-------|---------------|-------|
| GPT-5.2-Codex | 200K tokens | Standard, reliable |
| GPT-5.3-Codex | 200K tokens | Standard, reliable |
| Sonnet 4.5 | 200K tokens | Standard, reliable |
| Opus 4.5 | 200K tokens | Standard, reliable |
| **Opus 4.6** | **1M tokens** | Beta, 76% recall rate |
| **Gemini 3 Pro** | **1M tokens** | Native long-context |

**For documents >200K tokens:** Use Opus 4.6 (better recall) or Gemini 3 Pro (cheaper)

---

## Safety & Alignment Ratings

### Claude Models (Anthropic)
**Rating:** ğŸ›¡ï¸ğŸ›¡ï¸ğŸ›¡ï¸ğŸ›¡ï¸ğŸ›¡ï¸ Excellent
- Industry-leading Constitutional AI
- Strong refusal of harmful requests
- Excellent at nuanced safety decisions
- Less restrictive than necessary

### GPT Models (OpenAI)
**Rating:** ğŸ›¡ï¸ğŸ›¡ï¸ğŸ›¡ï¸ğŸ›¡ï¸ Very Good
- Strong safety training
- Sometimes over-cautious
- Clear reasoning for refusals
- Can be more restrictive

### Gemini Models (Google)
**Rating:** ğŸ›¡ï¸ğŸ›¡ï¸ğŸ›¡ï¸ Good
- Improving safety features
- Sometimes inconsistent
- Learning from feedback
- Still maturing

**Recommendation:** Use Claude for safety-critical applications

---

## Integration Features

### Streaming Support
âœ… All models support streaming  
âœ… Better UX for long responses  
âœ… Can cancel mid-generation  

### Function Calling
âœ… GPT models: Excellent (native)  
âœ… Claude models: Excellent (tool use)  
âœ… Gemini models: Good (improving)  

### Context Caching
âœ… Claude: Free caching on long contexts  
âœ… GPT: Prompt caching available  
âœ… Gemini: Caching features in development  

### Vision Support
âœ… All models support images  
âœ… Only Gemini supports native video  
âœ… Only Gemini supports native audio  

---

## Future Outlook (Next 6 Months)

### Q2 2026 Expected Releases
- **Gemini 3 Pro Stable** - Pricing may improve ($1.50/$10)
- **GPT-5.4** - Possible next iteration
- **Claude 5 Preview** - Anthropic's next generation

### Trends to Watch
1. **Cost decreasing** - Competition driving prices down
2. **Context expanding** - More models moving to 1M+ tokens
3. **Multimodal improving** - Video/audio becoming standard
4. **Speed increasing** - Inference optimizations across board

### Recommendation
- **Review this strategy quarterly**
- **Test new models as released**
- **Monitor cost/performance trends**
- **Be ready to adjust routing**

---

## Bottom Line Recommendations

### For Most Users
**Primary:** GPT-5.2-Codex (best cost/performance)  
**Fallback:** Claude Sonnet 4.5 (reliability)  
**Vision:** Gemini 3 Pro (multimodal)  
**Complex:** Claude Opus 4.5 (deep work)

### For Cost-Sensitive Users
**Everything:** GPT-5.2-Codex  
**Only exception:** Vision â†’ Gemini 3 Pro

### For Quality-First Users
**Chat:** Claude Sonnet 4.5  
**Code:** Claude Opus 4.5  
**Math:** GPT-5.2-Codex  
**Vision:** Gemini 3 Pro

### For Speed-First Users
**Everything:** GPT-5.3-Codex  
**Only exception:** Complex code â†’ Opus 4.5

---

**Last Updated:** February 7, 2026  
**Next Review:** May 7, 2026  
**Sources:** Official benchmarks, API documentation, independent testing
